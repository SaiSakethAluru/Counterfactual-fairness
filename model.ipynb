{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textcnn clp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpMD3xknCEPM",
        "colab_type": "code",
        "outputId": "74345607-cd48-49e2-d123-e8e715a05338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp_xMTxmCKjG",
        "colab_type": "code",
        "outputId": "0c830c27-8f98-4a1c-88fc-5e266e3a1b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random , re\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7RtBUFsCN48",
        "colab_type": "code",
        "outputId": "708c1020-3ea5-480f-c0b0-2faed8e3256a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if torch.cuda.is_available():      \n",
        "\tdevice = torch.device(\"cuda\")\n",
        "\tprint('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\tprint('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "\tprint('No GPU available, using the CPU instead.')\n",
        "\tdevice = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0LVFO_VX2mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# device = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwoGLNn3CQWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_val = 45\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "batchsize = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0nZ4_KGCS_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basepath = \"./drive/My Drive/AI Ethics Term Project/\"\n",
        "path = basepath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlQYkP3ZdkP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, V, D=100 ,C=1 ,Co= 32,Ks = [7,7,3,3,3],dropout=0.5):\n",
        "        super(TextCNN, self).__init__()\n",
        "        # self.args = args\n",
        "        \n",
        "        self.V = V\n",
        "        self.D = D\n",
        "        self.C = C\n",
        "        self.Ci = 1\n",
        "        self.Co = Co\n",
        "        self.Ks = Ks\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embed = nn.Embedding(self.V, self.D)\n",
        "        # self.word_embeddings.weight = nn.Parameter(weights, requires_grad=False)\n",
        "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(self.Ci, self.Co, (K, self.D)) for K in self.Ks])\n",
        "        '''\n",
        "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
        "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
        "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
        "        '''\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        self.fc1 = nn.Linear(len(self.Ks)*self.Co, self.C)\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)  # (N, W, D)\n",
        "        \n",
        "        # if self.args.static:\n",
        "            # x = Variable(x)\n",
        "\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "\n",
        "        x = torch.cat(x, 1)\n",
        "\n",
        "        '''\n",
        "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
        "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
        "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
        "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
        "        '''\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "        logit = self.fc1(x)  # (N, C)\n",
        "        return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWY37C-ARYsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_id_terms = ['lgbt',\n",
        " 'taoist',\n",
        " 'american',\n",
        " 'latina',\n",
        " 'asian',\n",
        " 'millenial',\n",
        " 'buddhist',\n",
        " 'hispanic',\n",
        " 'lesbian',\n",
        " 'canadian',\n",
        " 'indian',\n",
        " 'heterosexual',\n",
        " 'christian',\n",
        " 'male',\n",
        " 'younger',\n",
        " 'catholic',\n",
        " 'latino',\n",
        " 'latinx',\n",
        " 'transgender',\n",
        " 'muslim',\n",
        " 'female',\n",
        " 'chinese',\n",
        " 'sikh',\n",
        " 'deaf',\n",
        " 'paralyzed',\n",
        " 'homosexual',\n",
        " 'older',\n",
        " 'young',\n",
        " 'jewish',\n",
        " 'straight',\n",
        " 'protestant',\n",
        " 'old',\n",
        " 'bisexual',\n",
        " 'elderly',\n",
        " 'trans',\n",
        " ]\n",
        " \n",
        "\n",
        "test_id_terms = ['blind',\n",
        "                 'nonbinary',\n",
        "                 'queer',\n",
        "                 'gay',\n",
        "                 'lgbtq',\n",
        "                 'mexican',\n",
        "                 'european',\n",
        "                 'african',\n",
        "                 'teenage',\n",
        "                 'black',\n",
        "                 'white',\n",
        "                 'japanese',\n",
        "                 'african american',\n",
        "                 'middle eastern',\n",
        "                 'middle aged']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK-pWZX9QQYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(mode='train'):\n",
        "    if mode=='train':\n",
        "        train_df = pd.read_csv(basepath+'cleaned_train.csv')\n",
        "        # train_df = shuffle(train_df)\n",
        "        train_df = train_df.set_index(np.random.permutation(train_df.index))\n",
        "        train_df.reset_index(inplace=True, drop=True)\n",
        "        # train_df = train_df\n",
        "        train_len = int(0.8*train_df.shape[0])\n",
        "        val_df = train_df[train_len:]\n",
        "        train_df = train_df[:train_len]\n",
        "        return list(train_df['comment_text'].values),list(train_df['toxic'].values),list(val_df['comment_text'].values),list(val_df['toxic'])\n",
        "    if mode=='test':\n",
        "        test_df = pd.read_csv(basepath+'test_cleaned.csv')\n",
        "        return list(test_df['comment_text'].values),list(test_df['toxic'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEdx0yXVL9am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(path+'test_cleaned.csv')\n",
        "train_df = pd.read_csv(basepath+'cleaned_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeYJBanyIyir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = []\n",
        "train_texts,train_y,val_texts,val_y = load_data('train')\n",
        "test_texts,test_y = load_data('test')\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=True) #\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpVUcgxvRa75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(train_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_gWKDvlT57K",
        "colab_type": "code",
        "outputId": "0b8fde98-d75b-4bfb-cebb-24aa91e74d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.word_index[tokenizer.oov_token]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tiMZKTQTev9",
        "colab_type": "code",
        "outputId": "8fe94dd3-5540-4a77-c48a-8fbe7156ff01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= 5000}\n",
        "\n",
        "count=0\n",
        "for word in train_id_terms+test_id_terms:\n",
        "  if not tokenizer.word_index.get(word) or tokenizer.word_index.get(word)>5000:\n",
        "    count+=1\n",
        "print(count)\n",
        "\n",
        "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= 5000-count} # <= because tokenizer is 1 indexed\n",
        "\n",
        "for word in train_id_terms+test_id_terms:\n",
        "  if not tokenizer.word_index.get(word):\n",
        "    tokenizer.word_index[word] = 5000-count+1\n",
        "    count-=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiYRHqLpHH00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens = tokenizer.texts_to_sequences(train_id_terms)\n",
        "test_tokens = tokenizer.texts_to_sequences(test_id_terms)\n",
        "train_tokens = [i[0] for i in train_tokens]\n",
        "test_tokens = [i[0] for i in test_tokens]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JIdLyKtMZbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(train_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6W0Y1fGUvLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # tokenizer.word_index[tokenizer.oov_token]\n",
        "# for k,v in tokenizer.word_index.items():\n",
        "#   if v>=5000-24:\n",
        "#     print(k,v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnvwlc6ZOc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for word in train_id_terms+test_id_terms:\n",
        "#   print(word, tokenizer.word_index.get(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvuU5MbfWaGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_dataloader():\n",
        "    for i in range(0, len(train_data), batchsize):\n",
        "        yield torch.tensor(train_data[i:i+batchsize], device=device, dtype=torch.long),torch.tensor(train_y[i:i+batchsize],device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYyZ95PiJMuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_dataloader():\n",
        "    for i in range(0, len(val_data), batchsize):\n",
        "        yield torch.tensor(val_data[i:i+batchsize], device=device, dtype=torch.long),torch.tensor(val_y[i:i+batchsize],device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJJB51vUEbvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_dataloader():\n",
        "  for i in range(0,len(test_data),batchsize):\n",
        "    yield torch.tensor(test_data[i:i+batchsize],device=device,dtype=torch.long),torch.tensor(test_y[i:i+batchsize],device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8dCgWQzY0Ye",
        "colab_type": "code",
        "outputId": "1bb8c6ba-e8e5-4720-a1d7-f2f6dc3f025a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(tokenizer.word_index))\n",
        "print(tokenizer.num_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvw3bKtEDxC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # tokenizer.word_index.get('racist')\n",
        "\n",
        "# train_toxic = train_df[train_df['toxic']==1]\n",
        "# train_toxic_texts = list(train_toxic['comment_text'].values)\n",
        "\n",
        "# tk_temp = Tokenizer(num_words=1000, lower=True)\n",
        "# tk_temp.fit_on_texts(train_toxic_texts)\n",
        "\n",
        "# w =  sorted(tk_temp.word_counts.items(), key=lambda x:x[1], reverse=True)\n",
        "# # print(len(w))\n",
        "\n",
        "# count=1\n",
        "# temp = []\n",
        "# for k in w:\n",
        "#   if not tokenizer.word_index.get(k[0]):\n",
        "#     temp.append(k[0])\n",
        "#     # print(k[0], k[1])\n",
        "#     tokenizer.word_index[k[0]] = 5000+count\n",
        "#     count +=1 \n",
        "#   if count==1001:\n",
        "#     break\n",
        "\n",
        "# # print(temp)\n",
        "# print('No of added words ', len(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZD0Jd8ghASo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(tokenizer.num_words)\n",
        "# tokenizer.word_index.get('trump')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9riW_ATHXHQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYHrFox6V5p3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "train_data = pad_sequences(train_sequences, maxlen=100, padding='post')\n",
        "val_data = pad_sequences(val_sequences,maxlen=100,padding='post')\n",
        "test_data = pad_sequences(test_sequences, maxlen=100, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCzUgyTkXBEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXk0JPHsCaSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, name, val_loss=0):\n",
        "  state = {\n",
        "      'model':model.state_dict(),\n",
        "      'optimizer': optimizer.state_dict(),\n",
        "      'val_loss': val_loss\n",
        "  }\n",
        "  torch.save(state, path+name)\n",
        "\n",
        "def load_model(model, name):\n",
        "  state = torch.load(path+name)\n",
        "  model.load_state_dict(state['model'])\n",
        "  optimizer.load_state_dict(state['optimizer'])\n",
        "  print('Validation loss of the model is ', state.get('val_loss'))\n",
        "  return state.get('val_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYVEyt8DuMB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_cfs(x):\n",
        "    cf_x = []\n",
        "    cx = x.detach().cpu()\n",
        "    tokens= train_tokens.copy()\n",
        "    for i in cx:\n",
        "        # indices = torch.ones_like(i, dtype = torch.uint8, device =device)\n",
        "        i = i.tolist()\n",
        "        ids = np.intersect1d(i, tokens).tolist()\n",
        "        if len(ids)>0:\n",
        "            ind = i.index(ids[0])\n",
        "            tokens.remove(ids[0])\n",
        "            i[ind] = random.choice(tokens)\n",
        "        cf_x.append(i)\n",
        "    return torch.tensor(cf_x,device=device,dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD1VSIxb3SRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_clp_loss(x):\n",
        "  fx = textcnn(x)\n",
        "  f_cfx = textcnn(generate_cfs(x))\n",
        "  loss = torch.sum(abs(fx-f_cfx), dim=0)/x.shape[0]\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNhGkiQ0Mwni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_clp_nontoxic_loss(x, y):\n",
        "  y_invert = y\n",
        "  y_invert[y_invert==0]=2\n",
        "  y_invert[y_invert==1]=0\n",
        "  y_invert[y_invert==2]=1\n",
        "  fx = (textcnn(x))\n",
        "  f_cfx = (textcnn(generate_cfs(x)))\n",
        "  # print(abs(fx-f_cfx).shape , y_invert.shape)\n",
        "  loss = torch.sum(abs(fx-f_cfx).squeeze(1) * y_invert, dim=0)/x.shape[0]\n",
        "  # print(loss.shape)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eSD393D2MVI",
        "colab_type": "code",
        "outputId": "bdb57c94-042e-4177-e6e2-37df8b60f498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(train_y))\n",
        "print(sum(train_y))\n",
        "pw = (len(train_y) - sum(train_y))/sum(train_y)\n",
        "print(pw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127656\n",
            "12257\n",
            "9.414946561148732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYlbay5bW6Pb",
        "colab_type": "code",
        "outputId": "b3c79713-6a13-475d-d522-1e3037d3d6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# class_wt = torch.tensor(compute_class_weight('balanced',np.unique(train_y),train_y),device=device,dtype=torch.float32)\n",
        "textcnn = TextCNN(V = (tokenizer.num_words))\n",
        "if torch.cuda.is_available():\n",
        "  textcnn.cuda()\n",
        "\n",
        "class_wt = torch.tensor(compute_class_weight('balanced',np.unique(train_y),train_y),device=device,dtype=torch.float)\n",
        "\n",
        "# print(class_wt)\n",
        "pw = class_wt[1]/class_wt[0]\n",
        "print(pw)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight = pw) # with sigmoid # pos_weight = pw\n",
        "# clp_loss_criterion = nn.L1Loss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(textcnn.parameters(),lr =1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(9.4149, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yumbsr8AErTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softmax = torch.nn.Softmax(dim=1)\n",
        "sigmoid= torch.nn.Sigmoid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9328S7Kyd_PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load_model(textcnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1t4P-ltZWAB",
        "colab_type": "code",
        "outputId": "217622c9-269d-4235-86d9-d503746f718a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Total number of trainable parameters: ', sum(p.numel() for p in textcnn.parameters() if p.requires_grad)/float(1000000), 'M')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of trainable parameters:  0.573921 M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0EQOCa7KJFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_clp = False\n",
        "use_clp_nontoxic= True # only lambda 1 for this\n",
        "lambda_clp =1  # 0.05,1,5\n",
        "name = 'textcnn_clpnontoxic_lam1.pt'\n",
        "min_val_loss = float('INF')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N75CLbXt3roJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# min_val_loss = load_model(textcnn, name)\n",
        "# print(min_val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3AtU6oj3xns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.96)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxeKXCI3lxaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = torch.tensor([0.56, 0.54, 0.22])\n",
        "# (a>=0.5).long()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "936YiUcFXK9R",
        "colab_type": "code",
        "outputId": "f6c14798-5275-4306-e009-5326bd116131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "true_y = []\n",
        "pred_y = []\n",
        "state = {}\n",
        "\n",
        "for epoch in range(15):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch+1,15))\n",
        "    t0 = time.time()\n",
        "    textcnn.train()\n",
        "    total_loss = 0\n",
        "    total_steps = 0\n",
        "    pred_logits = []\n",
        "    one_hot_y = []\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    pred_logits = []\n",
        "\n",
        "    for step,batch in (enumerate(train_dataloader())):\n",
        "\n",
        "        total_steps+=1\n",
        "        # if step % 40 == 0 and not step == 0:\n",
        "        #         # Calculate elapsed time in minutes.\n",
        "        #         elapsed = format_time(time.time() - t0)\n",
        "        x,y = batch\n",
        "        cf_x = generate_cfs(x)\n",
        "        textcnn.zero_grad()\n",
        "        fx = (textcnn(x)).squeeze(1)\n",
        "\n",
        "    \n",
        "        if use_clp:\n",
        "          loss = criterion(fx,y.float()) + lambda_clp * compute_clp_loss(x)\n",
        "          # print(criterion(fx,y.float()).item()  , lambda_clp * compute_clp_loss(x)  )\n",
        "        elif use_clp_nontoxic:\n",
        "          loss = criterion(fx,y.float()) + lambda_clp * compute_clp_nontoxic_loss(x, y)\n",
        "          # print( criterion(fx,y.float()).shape,   (lambda_clp * compute_clp_nontoxic_loss(x, y)).shape )\n",
        "        else:\n",
        "          loss = criterion(fx,y.float())\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(textcnn.parameters(), 0.7)\n",
        "        optimizer.step()\n",
        "        \n",
        "        true_label_vals = y.to('cpu').numpy()\n",
        "        true_labels += list(true_label_vals.flatten())\n",
        "\n",
        "        pred_labels += list((fx>=0.5).long().detach().cpu().numpy())\n",
        "        pred_logits.extend(fx.detach().cpu().numpy())\n",
        "        # one_hot_y.extend(np.eye(2)[true_label_vals])\n",
        "        \n",
        "    avg_train_loss = total_loss / total_steps\n",
        "\n",
        "    matrix = confusion_matrix(true_labels, pred_labels)\n",
        "    class_acc = matrix.diagonal()/matrix.sum(axis=1)\n",
        "\n",
        "    print('Training loss: ',avg_train_loss)\n",
        "    print('Accuracy: ',accuracy_score(true_labels,pred_labels))\n",
        "    print('Macro F1 score: ',f1_score(true_labels,pred_labels,average='macro'))\n",
        "    print('ROC_AUC Score: ',roc_auc_score(true_labels , pred_logits ))\n",
        "    print(matrix)\n",
        "    print('Class accuracies: ', class_acc)\n",
        "    #############################test data #####################################\n",
        "    textcnn.eval()\n",
        "    pred_logits = []\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    pred_scores = []\n",
        "    with torch.no_grad():\n",
        "      for x,y in test_dataloader():\n",
        "        pred_y = textcnn(x)\n",
        "        fx = (pred_y).squeeze(1)\n",
        "        fx = sigmoid(fx)\n",
        "\n",
        "        true_label_vals = y.to('cpu').numpy()\n",
        "        true_labels += list(true_label_vals.flatten())\n",
        "\n",
        "        pred_labels += list((fx>=0.5).long().detach().cpu().numpy())\n",
        "        pred_logits.extend(fx.detach().cpu().numpy())\n",
        "        # one_hot_y.extend(np.eye(2)[true_label_vals])\n",
        "\n",
        "    matrix = confusion_matrix(true_labels, pred_labels)\n",
        "    class_acc = matrix.diagonal()/matrix.sum(axis=1)\n",
        "    print('Test Accuracy: ',accuracy_score(true_labels,pred_labels))\n",
        "    print('Test Macro F1 score: ',f1_score(true_labels,pred_labels,average='macro'))\n",
        "    print('Test ROC AUC Score: ',roc_auc_score(true_labels,  pred_logits  ))\n",
        "    print(matrix)\n",
        "    print('Class accuracies: ', class_acc)\n",
        "    ###################################### val data ###############################################\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    pred_scores = []\n",
        "    pred_logits = []\n",
        "    val_loss = 0\n",
        "    j = 0\n",
        "    with torch.no_grad():\n",
        "      for x,y in val_dataloader():\n",
        "        pred_y = textcnn(x)\n",
        "        fx = (pred_y).squeeze(1)\n",
        "\n",
        "        if use_clp:\n",
        "          loss = criterion(fx,y.float()) + lambda_clp * compute_clp_loss(x)\n",
        "        elif use_clp_nontoxic:\n",
        "          loss = criterion(fx,y.float()) + lambda_clp * compute_clp_nontoxic_loss(x, y)\n",
        "        else:\n",
        "          loss = criterion(fx,y.float())\n",
        "\n",
        "        fx = sigmoid(fx)\n",
        "        true_label_vals = y.to('cpu').numpy()\n",
        "        true_labels += list(true_label_vals.flatten())\n",
        "\n",
        "        pred_labels += list((fx>=0.5).long().detach().cpu().numpy())\n",
        "        pred_logits.extend(fx.detach().cpu().numpy())\n",
        "        # one_hot_y.extend(np.eye(2)[true_label_vals])\n",
        "\n",
        "        val_loss += loss.item()\n",
        "        j = j+1\n",
        "    \n",
        "    val_loss = val_loss/j\n",
        "    if(val_loss<min_val_loss):\n",
        "        save_model(textcnn, name , val_loss)\n",
        "        min_val_loss = val_loss\n",
        "\n",
        "    matrix = confusion_matrix(true_labels, pred_labels)\n",
        "    class_acc = matrix.diagonal()/matrix.sum(axis=1)\n",
        "    print('Val loss: ', val_loss)    \n",
        "    print('Val Accuracy: ',accuracy_score(true_labels,pred_labels))\n",
        "    print('Val Macro F1 score: ',f1_score(true_labels,pred_labels,average='macro'))\n",
        "    print('Val ROC AUC Score: ',roc_auc_score(true_labels , pred_logits))\n",
        "    print(matrix)\n",
        "    print('Class accuracies: ', class_acc)\n",
        "    print('\\n Time elapsed: ', time.time()-t0)\n",
        "    scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 15 ========\n",
            "Training loss:  0.9664912276847619\n",
            "Accuracy:  0.07308704643730024\n",
            "Macro F1 score:  0.07302457114110733\n",
            "ROC_AUC Score:  0.09901656425948382\n",
            "[[  5189   7068]\n",
            " [111258   4141]]\n",
            "Class accuracies:  [0.42334992 0.03588419]\n",
            "Test Accuracy:  0.8910501438553227\n",
            "Test Macro F1 score:  0.6693913496670884\n",
            "Test ROC AUC Score:  0.7758926850741007\n",
            "[[83202  6447]\n",
            " [ 4156  3515]]\n",
            "Class accuracies:  [0.9280862  0.45821927]\n",
            "Val loss:  0.5648610510066421\n",
            "Val Accuracy:  0.06523578254739151\n",
            "Val Macro F1 score:  0.06443794453049465\n",
            "Val ROC AUC Score:  0.04541378108711764\n",
            "[[  575  2462]\n",
            " [27371  1507]]\n",
            "Class accuracies:  [0.18933158 0.05218505]\n",
            "\n",
            " Time elapsed:  40.09598970413208\n",
            "======== Epoch 2 / 15 ========\n",
            "Training loss:  0.6610022707541187\n",
            "Accuracy:  0.0516701134298427\n",
            "Macro F1 score:  0.05160643834943955\n",
            "ROC_AUC Score:  0.04007848925718592\n",
            "[[  2775   9482]\n",
            " [111578   3821]]\n",
            "Class accuracies:  [0.22640124 0.03311121]\n",
            "Test Accuracy:  0.8987053020961776\n",
            "Test Macro F1 score:  0.6909947096024164\n",
            "Test ROC AUC Score:  0.8116942675312614\n",
            "[[83626  6023]\n",
            " [ 3835  3836]]\n",
            "Class accuracies:  [0.93281576 0.50006518]\n",
            "Val loss:  0.5207671385728764\n",
            "Val Accuracy:  0.0609117969606768\n",
            "Val Macro F1 score:  0.0602294126178782\n",
            "Val ROC AUC Score:  0.03943405321486554\n",
            "[[  542  2495]\n",
            " [27476  1402]]\n",
            "Class accuracies:  [0.17846559 0.04854907]\n",
            "\n",
            " Time elapsed:  40.11522626876831\n",
            "======== Epoch 3 / 15 ========\n",
            "Training loss:  0.6016528946116455\n",
            "Accuracy:  0.049335714733345866\n",
            "Macro F1 score:  0.04924830747890712\n",
            "ROC_AUC Score:  0.034288200235079676\n",
            "[[  2537   9720]\n",
            " [111638   3761]]\n",
            "Class accuracies:  [0.20698376 0.03259127]\n",
            "Test Accuracy:  0.9020756267981915\n",
            "Test Macro F1 score:  0.6917994892829618\n",
            "Test ROC AUC Score:  0.8178066906945867\n",
            "[[84088  5561]\n",
            " [ 3969  3702]]\n",
            "Class accuracies:  [0.93796919 0.48259679]\n",
            "Val loss:  0.5133204159433234\n",
            "Val Accuracy:  0.059219802600658\n",
            "Val Macro F1 score:  0.05867470725904651\n",
            "Val ROC AUC Score:  0.03884652710984726\n",
            "[[  561  2476]\n",
            " [27549  1329]]\n",
            "Class accuracies:  [0.18472176 0.04602119]\n",
            "\n",
            " Time elapsed:  40.43241763114929\n",
            "======== Epoch 4 / 15 ========\n",
            "Training loss:  0.571435790178471\n",
            "Accuracy:  0.04722848906436047\n",
            "Macro F1 score:  0.047151026431565754\n",
            "ROC_AUC Score:  0.031116455644273608\n",
            "[[  2439   9818]\n",
            " [111809   3590]]\n",
            "Class accuracies:  [0.19898833 0.03110946]\n",
            "Test Accuracy:  0.9015926839293054\n",
            "Test Macro F1 score:  0.6918753312854964\n",
            "Test ROC AUC Score:  0.8217734908986049\n",
            "[[84016  5633]\n",
            " [ 3944  3727]]\n",
            "Class accuracies:  [0.93716606 0.48585582]\n",
            "Val loss:  0.514827756998773\n",
            "Val Accuracy:  0.05884380385398715\n",
            "Val Macro F1 score:  0.0583041594575741\n",
            "Val ROC AUC Score:  0.03966528383243321\n",
            "[[  557  2480]\n",
            " [27557  1321]]\n",
            "Class accuracies:  [0.18340468 0.04574417]\n",
            "\n",
            " Time elapsed:  40.520299434661865\n",
            "======== Epoch 5 / 15 ========\n",
            "Training loss:  0.551159759168338\n",
            "Accuracy:  0.04559911010841637\n",
            "Macro F1 score:  0.04552151500316388\n",
            "ROC_AUC Score:  0.029537714058179187\n",
            "[[  2335   9922]\n",
            " [111913   3486]]\n",
            "Class accuracies:  [0.19050339 0.03020823]\n",
            "Test Accuracy:  0.9063501849568434\n",
            "Test Macro F1 score:  0.6934065895913961\n",
            "Test ROC AUC Score:  0.8205333140388029\n",
            "[[84656  4993]\n",
            " [ 4121  3550]]\n",
            "Class accuracies:  [0.94430501 0.46278191]\n",
            "Val loss:  0.5233014435889964\n",
            "Val Accuracy:  0.05686981043396522\n",
            "Val Macro F1 score:  0.05648443963922058\n",
            "Val ROC AUC Score:  0.040497301296567575\n",
            "[[  585  2452]\n",
            " [27648  1230]]\n",
            "Class accuracies:  [0.1926243  0.04259298]\n",
            "\n",
            " Time elapsed:  40.63219690322876\n",
            "======== Epoch 6 / 15 ========\n",
            "Training loss:  0.5369974540513859\n",
            "Accuracy:  0.04468258444569781\n",
            "Macro F1 score:  0.044617207777001094\n",
            "ROC_AUC Score:  0.029458485133068143\n",
            "[[  2324   9933]\n",
            " [112019   3380]]\n",
            "Class accuracies:  [0.18960594 0.02928968]\n",
            "Test Accuracy:  0.9076859843814221\n",
            "Test Macro F1 score:  0.6920704713775558\n",
            "Test ROC AUC Score:  0.8182078416489296\n",
            "[[84886  4763]\n",
            " [ 4221  3450]]\n",
            "Class accuracies:  [0.94687057 0.4497458 ]\n",
            "Val loss:  0.5383661040562189\n",
            "Val Accuracy:  0.05589848033839887\n",
            "Val Macro F1 score:  0.05558657095261284\n",
            "Val ROC AUC Score:  0.04221947026678354\n",
            "[[  602  2435]\n",
            " [27696  1182]]\n",
            "Class accuracies:  [0.19822193 0.04093081]\n",
            "\n",
            " Time elapsed:  40.46657609939575\n",
            "======== Epoch 7 / 15 ========\n",
            "Training loss:  0.5249957549766192\n",
            "Accuracy:  0.042050510747634266\n",
            "Macro F1 score:  0.04200662661430273\n",
            "ROC_AUC Score:  0.03104573005112859\n",
            "[[  2252  10005]\n",
            " [112283   3116]]\n",
            "Class accuracies:  [0.18373175 0.02700197]\n",
            "Test Accuracy:  0.9091759145088368\n",
            "Test Macro F1 score:  0.6896698450453936\n",
            "Test ROC AUC Score:  0.8149342481448881\n",
            "[[85165  4484]\n",
            " [ 4355  3316]]\n",
            "Class accuracies:  [0.94998271 0.43227741]\n",
            "Val loss:  0.5521383179661506\n",
            "Val Accuracy:  0.05430048566504778\n",
            "Val Macro F1 score:  0.05410823203813346\n",
            "Val ROC AUC Score:  0.0437428592389046\n",
            "[[  639  2398]\n",
            " [27784  1094]]\n",
            "Class accuracies:  [0.210405   0.03788351]\n",
            "\n",
            " Time elapsed:  40.603004932403564\n",
            "======== Epoch 8 / 15 ========\n",
            "Training loss:  0.515672622195312\n",
            "Accuracy:  0.040781475214639346\n",
            "Macro F1 score:  0.04074976190474116\n",
            "ROC_AUC Score:  0.03124073190281882\n",
            "[[  2236  10021]\n",
            " [112429   2970]]\n",
            "Class accuracies:  [0.18242637 0.02573679]\n",
            "Test Accuracy:  0.9088368269625976\n",
            "Test Macro F1 score:  0.6864544985497545\n",
            "Test ROC AUC Score:  0.8128208450215941\n",
            "[[85204  4445]\n",
            " [ 4427  3244]]\n",
            "Class accuracies:  [0.95041774 0.42289141]\n",
            "Val loss:  0.5575621445366519\n",
            "Val Accuracy:  0.054927150242832526\n",
            "Val Macro F1 score:  0.05471951872710738\n",
            "Val ROC AUC Score:  0.04519683740777884\n",
            "[[  640  2397]\n",
            " [27765  1113]]\n",
            "Class accuracies:  [0.21073428 0.03854145]\n",
            "\n",
            " Time elapsed:  40.46891808509827\n",
            "======== Epoch 9 / 15 ========\n",
            "Training loss:  0.5049153197603417\n",
            "Accuracy:  0.03950460612897161\n",
            "Macro F1 score:  0.0394744733954759\n",
            "ROC_AUC Score:  0.030019698679908814\n",
            "[[  2164  10093]\n",
            " [112520   2879]]\n",
            "Class accuracies:  [0.17655217 0.02494822]\n",
            "Test Accuracy:  0.908734073160707\n",
            "Test Macro F1 score:  0.6853141392355039\n",
            "Test ROC AUC Score:  0.810201605377704\n",
            "[[85220  4429]\n",
            " [ 4453  3218]]\n",
            "Class accuracies:  [0.95059621 0.41950202]\n",
            "Val loss:  0.5673426012984497\n",
            "Val Accuracy:  0.05430048566504778\n",
            "Val Macro F1 score:  0.05413117006794257\n",
            "Val ROC AUC Score:  0.046839424825426274\n",
            "[[  653  2384]\n",
            " [27798  1080]]\n",
            "Class accuracies:  [0.21501482 0.03739871]\n",
            "\n",
            " Time elapsed:  40.373197078704834\n",
            "======== Epoch 10 / 15 ========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-3125b6ae0b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0;31m# print(criterion(fx,y.float()).item()  , lambda_clp * compute_clp_loss(x)  )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0muse_clp_nontoxic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_clp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcompute_clp_nontoxic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m           \u001b[0;31m# print( criterion(fx,y.float()).shape,   (lambda_clp * compute_clp_nontoxic_loss(x, y)).shape )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-9e156b05d656>\u001b[0m in \u001b[0;36mcompute_clp_nontoxic_loss\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0my_invert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_invert\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtextcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mf_cfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtextcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_cfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;31m# print(abs(fx-f_cfx).shape , y_invert.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mf_cfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_invert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-0dfeb6fab406>\u001b[0m in \u001b[0;36mgenerate_cfs\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# indices = torch.ones_like(i, dtype = torch.uint8, device =device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mintersect1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36mintersect1d\u001b[0;34m(ar1, ar2, assume_unique, return_indices)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \"\"\"\n\u001b[1;32m    397\u001b[0m     \u001b[0mar1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mar2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYWTCjeHOM-",
        "colab_type": "code",
        "outputId": "d4470403-ac31-41d3-f5ca-9102f5fe95ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "load_model(textcnn, name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss of the model is  0.5133204159433234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5133204159433234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iA4Bp4Ebsot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "pred_logits = []\n",
        "with torch.no_grad():\n",
        "  for (x,y) in test_dataloader():\n",
        "    pred_y = textcnn(x) # 64,2\n",
        "    true_label_vals = y.detach().to('cpu').numpy()\n",
        "    pred_label_vals = sigmoid(pred_y)\n",
        "    true_labels.extend(true_label_vals)\n",
        "    t = (pred_label_vals>=0.5).long()\n",
        "    pred_labels += t.detach().cpu()\n",
        "    pred_logits += pred_label_vals.detach().cpu()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa_U7GEhpj8q",
        "colab_type": "code",
        "outputId": "eefc6d9a-5b48-4751-f908-e8fd63a2566d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "accuracy = accuracy_score(true_labels,pred_labels)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(true_labels,pred_labels)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(true_labels,pred_labels)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(true_labels,pred_labels,average='macro')\n",
        "print('F1 score: %f' % f1)\n",
        "print(\"confusion matrix \", confusion_matrix(true_labels, pred_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.900473\n",
            "Precision: 0.393149\n",
            "Recall: 0.483249\n",
            "F1 score: 0.689505\n",
            "confusion matrix  [[83927  5722]\n",
            " [ 3964  3707]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bOhD5CipmGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import roc_curve\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# one_hot_y = np.eye(2)[test_y]\n",
        "# pred_logits = [y.numpy() for y in pred_logits]\n",
        "# auc = roc_auc_score(one_hot_y, pred_logits)\n",
        "# # summarize scores\n",
        "# print('Accuracy: ROC AUC=%.3f' % (auc))\n",
        "# # calculate roc curves\n",
        "# # ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
        "# fpr, tpr, _ = roc_curve(one_hot_y, pred_logits)\n",
        "# # plot the roc curve for the model\n",
        "# plt.plot(fpr, tpr, marker='.',label='roc curve')\n",
        "# x1,x2,y1,y2 = plt.axis()\n",
        "# plt.axis((x1,x2,0.8,1.0))\n",
        "# # axis labels\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# # show the legend\n",
        "# plt.legend()\n",
        "# # show the plot\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz7reUh4BYDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oYNsAKiLtzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_nontoxic = test_df[test_df['toxic']==0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-YLhY2eLyTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_nontoxic_texts = list(test_nontoxic['comment_text'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1xyxx8WPvbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(train_id_terms))\n",
        "# count=0\n",
        "# for word in train_id_terms:\n",
        "#   if tokenizer.word_index.get(word) and tokenizer.word_index.get(word)<=5000:\n",
        "#     print(word , tokenizer.word_index.get(word))\n",
        "#     count+=1\n",
        "# print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKIrKiy4QKvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for word in test_id_terms:\n",
        "#   print(word , tokenizer.word_index.get(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx0exE9WI8Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CTF_gap(model,data,id_terms):\n",
        "  # model - pytorch model\n",
        "  # data - raw text -- list\n",
        "  # list of id terms to replace. \n",
        "  model.eval()\n",
        "  total_ctf_gap = 0\n",
        "  total_inputs = 0\n",
        "  dum='iamsurya'\n",
        "  dumm='youarechan'\n",
        "  count = 0\n",
        "  print('Total sentences in dataset are: ', len(data)) \n",
        "  for i in range(len(data)):\n",
        "    st = data[i]\n",
        "    words = st.split()\n",
        "    if(len(words)>10):\n",
        "      continue  ## The paper says ctf is calculated only for those inputs that have less than 10 tokens.\n",
        "    sentences = []\n",
        "    sentences.append(data[i])\n",
        "    \n",
        "    ind_ctf = 0\n",
        "    done = []\n",
        "    for w in id_terms:\n",
        "      if w in words:\n",
        "        done.append(w)\n",
        "        for wr in id_terms:\n",
        "          if wr not in done:\n",
        "            new = re.sub(r\"\\b%ss?\\b\" % w,dum,st)\n",
        "            new = re.sub(r\"\\b%ss?\\b\" % wr,dumm,new)\n",
        "            new = new.replace(dum,wr)\n",
        "            new = new.replace(dumm,w)\n",
        "            sentences.append(new)\n",
        "    \n",
        "    # No counterfactuals to consider\n",
        "    if(len(sentences)<2):\n",
        "      continue\n",
        "    count += 1\n",
        "    total_inputs += 1\n",
        "    sent_sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    sent_data = pad_sequences(sent_sequences, maxlen=10, padding='post')\n",
        "    # print(sent_data)\n",
        "\n",
        "    sent_tensors = torch.tensor(sent_data,device=device,dtype=torch.long)\n",
        "    with torch.no_grad():\n",
        "      predictions = model(sent_tensors)\n",
        "      predictions = sigmoid(predictions)\n",
        "      # predictions = torch.max(predictions, dim=1)[1]\n",
        "\n",
        "    for i in range(1,len(predictions)):\n",
        "      ind_ctf += abs(predictions[0] - predictions[i])\n",
        "\n",
        "    ind_ctf = ind_ctf.detach().cpu().numpy()\n",
        "    ind_ctf = float(ind_ctf)/float(len(predictions)-1)\n",
        "    total_ctf_gap += ind_ctf\n",
        "\n",
        "  print('Total sentences used for ctf gap are: ', count)\n",
        "  return total_ctf_gap/total_inputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EgkNDNMPaKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sigmoid(torch.tensor([5.1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6GBku7qLz-E",
        "colab_type": "code",
        "outputId": "9433373d-c670-4e4f-d22a-7c6aa883b35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ctf = CTF_gap(textcnn, test_nontoxic_texts ,train_id_terms) # eval nt\n",
        "print(ctf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sentences in dataset are:  89649\n",
            "Total sentences used for ctf gap are:  136\n",
            "0.02285862796434543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEVBnPFZeuq4",
        "colab_type": "code",
        "outputId": "8c9ec44a-19c0-4801-b717-8213c1e608a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ctf = CTF_gap(textcnn, test_nontoxic_texts ,test_id_terms) # for table 2\n",
        "print(ctf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sentences in dataset are:  89649\n",
            "Total sentences used for ctf gap are:  52\n",
            "0.12122252219162151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ttw8oRKgeE",
        "colab_type": "code",
        "outputId": "079646b3-8cfa-4fd3-9748-dc56abeaaac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df = pd.read_csv(path+'synthetic_nontoxic.csv')\n",
        "nontoxic_syn_texts = list(df['Text'].values)\n",
        "ctf = CTF_gap(textcnn, nontoxic_syn_texts, train_id_terms)\n",
        "print(ctf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sentences in dataset are:  44436\n",
            "Total sentences used for ctf gap are:  32007\n",
            "0.006586309471391171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p98u7qvrMFOH",
        "colab_type": "code",
        "outputId": "e2b7b09b-9fc1-4764-e134-1cdd480c8788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df = pd.read_csv(path+'synthetic_toxic.csv')\n",
        "toxic_syn_texts = list(df['Text'].values)\n",
        "ctf = CTF_gap(textcnn, toxic_syn_texts, train_id_terms)\n",
        "print(ctf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sentences in dataset are:  45047\n",
            "Total sentences used for ctf gap are:  30578\n",
            "0.014438790005869746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU_-cCvmvIFY",
        "colab_type": "text"
      },
      "source": [
        "TPR,TNR gaps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spEXc_KnG11L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_tokens = train_id_terms + test_id_terms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1FmfPcFvQ6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_list={}\n",
        "for x in id_tokens:\n",
        "  dict_list[x]=[0,0,0,0] #tp,fp,fn,tn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUgA4pLUvXQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize = 1\n",
        "def test_loader():\n",
        "    for i in range(0, len(test_df),batchsize):\n",
        "        id_dict={}\n",
        "        count=0\n",
        "        for x in id_tokens:\n",
        "          if ((x in test_texts[i].split() or (len(x.split())==2) and x in test_texts[i])):\n",
        "            id_dict[x]=1\n",
        "            count=count+1\n",
        "          else:\n",
        "            id_dict[x]=0\n",
        "        if (count==0):\n",
        "          continue\n",
        "        yield torch.tensor(test_data[i:i+batchsize], device=device, dtype=torch.long),torch.tensor(test_y[i:i+batchsize],device=device),id_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZKGKmSvvc0U",
        "colab_type": "code",
        "outputId": "8fc7ac9b-6c73-4b24-bd87-4f1b03234e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "true_y = []\n",
        "pred_y = []\n",
        "t0 = time.time()\n",
        "textcnn.eval()\n",
        "total_loss = 0\n",
        "total_steps = 0\n",
        "pred_labels = []\n",
        "true_labels = []\n",
        "for batch in (test_loader()):\n",
        "    total_steps+=1\n",
        "    x,y,dct = batch\n",
        "    lst = [k for k,v in dct.items() if v == 1]\n",
        "    with torch.no_grad():\n",
        "      fx = textcnn(x).squeeze(1)\n",
        "    loss = criterion(fx,y.float())\n",
        "    fx = sigmoid(fx)\n",
        "    total_loss += loss.item()        \n",
        "    true_label_vals = y.to('cpu').numpy()\n",
        "    pred_label_vals = (fx>=0.5).long().detach().cpu().numpy()\n",
        "    pred = pred_label_vals\n",
        "    true = true_label_vals\n",
        "    if(true==1 and pred==1):\n",
        "      for x in lst:\n",
        "        dict_list[x][0]+=1\n",
        "    elif(true==1 and pred==0): # false positive\n",
        "      for x in lst:\n",
        "        dict_list[x][1]+=1\n",
        "    elif(true==0 and pred==1): \n",
        "      for x in lst:\n",
        "        dict_list[x][2]+=1\n",
        "    elif(true==0 and pred==0):\n",
        "      for x in lst:\n",
        "        dict_list[x][3]+=1\n",
        "    true_labels += list(true_label_vals.flatten())\n",
        "    pred_labels += list(pred_label_vals)\n",
        "avg_train_loss = total_loss / total_steps\n",
        "print('avg_test_loss: ',avg_train_loss)\n",
        "print('Accuracy: ',accuracy_score(true_labels,pred_labels))\n",
        "true_y.extend(true_labels)\n",
        "pred_y.extend(pred_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_test_loss:  1.341417303014786\n",
            "Accuracy:  0.8615069679552791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm_kkuYow7VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpr={}\n",
        "for x in dict_list:\n",
        "  p=dict_list[x][0]+dict_list[x][2]\n",
        "  if p==0:\n",
        "    tpr[x]=0\n",
        "  else:\n",
        "    tpr[x]=dict_list[x][0]/p\n",
        "tnr={}\n",
        "for x in dict_list:\n",
        "  n=dict_list[x][1]+dict_list[x][3]\n",
        "  if n==0:\n",
        "    tnr[x]=0\n",
        "  else:\n",
        "    tnr[x]=dict_list[x][3]/n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI_4guYexEpV",
        "colab_type": "code",
        "outputId": "d3daa9ee-b445-4d8f-abe7-aa044fe80445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tpr_gap=0\n",
        "tnr_gap=0\n",
        "done=[]\n",
        "\n",
        "for x in tpr:\n",
        "  done.append(x)\n",
        "  for y in tpr:\n",
        "    if y not in done:\n",
        "      tpr_gap+=abs(tpr[x]-tpr[y])\n",
        "      tnr_gap+=abs(tnr[x]-tnr[y])\n",
        "\n",
        "\n",
        "tpr_gap/=1225\n",
        "tnr_gap/=1225\n",
        "print('TNR gap: ',tnr_gap)\n",
        "print('TPR gap: ',tpr_gap)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TNR gap:  0.15648930960634064\n",
            "TPR gap:  0.26062330697187364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Or3VYPS7slQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
